{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Development - Braindecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from einops import rearrange\n",
    "\n",
    "# Add the parent directory to the path so Python can find 'scripts'\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Reload the modules to get the latest changes\n",
    "import script.myModules.models.pytorch_lightning as pm  # noqa: E402\n",
    "import script.myModules.utils.data_utils as du  # noqa: E402\n",
    "import script.myModules.utils.utility as ut  # noqa: E402\n",
    "importlib.reload(du)\n",
    "importlib.reload(pm)\n",
    "\n",
    "# ut.set_seed(42)\n",
    "pl.seed_everything(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count: 1, CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "gpu_count = ut.cuda_device_count()\n",
    "cuda_available = ut.cuda_is_available()\n",
    "print(f'GPU count: {gpu_count}, CUDA available: {cuda_available}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Truncated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fNIRSDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path, task_type, batch_size=32, oversampling=False):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.task_type = task_type\n",
    "        self.batch_size = batch_size\n",
    "        self.oversampling = oversampling\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # Load fnirs data and create labels\n",
    "        fNIRS_data_dict = du.load_concatenated_fNIRS_data(self.data_path, self.task_type)\n",
    "        self.data, self.labels = du.create_data_and_labels(fNIRS_data_dict)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Split the data into train and test sets\n",
    "        data_HbO = self.data[:, :23]\n",
    "        self.train_data, self.test_data, self.train_labels, self.test_labels = train_test_split(\n",
    "            data_HbO, self.labels, test_size=0.2, stratify=self.labels, random_state=42\n",
    "        )\n",
    "\n",
    "        # Check the shape of the training data\n",
    "        num_subjects, num_channels, num_timepoints = self.train_data.shape\n",
    "        print(f\"Original train data shape: {self.train_data.shape}\")\n",
    "\n",
    "        # Use einops to reshape the 3D data to 2D: (samples, channels * time_points)\n",
    "        reshaped_train_data = rearrange(self.train_data, 's c t -> s (c t)')\n",
    "\n",
    "        if self.oversampling:\n",
    "            # Apply SMOTE to the reshaped data\n",
    "            smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "            reshaped_train_data, self.train_labels = smote.fit_resample(reshaped_train_data, self.train_labels)\n",
    "\n",
    "            # Use einops to reshape the data back to 3D: (samples, channels, time_points)\n",
    "            self.train_data = rearrange(reshaped_train_data, 's (c t) -> s c t', c=num_channels, t=num_timepoints)\n",
    "\n",
    "            # Print the new shape and class distribution after SMOTE\n",
    "            print(f\"Reshaped train data after SMOTE: {self.train_data.shape}\")\n",
    "            print(f\"Class distribution after SMOTE: {Counter(self.train_labels)}\")\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Create dataset and dataloader for training data\n",
    "        train_dataset = self.fNIRSDataset(self.train_data, self.train_labels)\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # Create dataset and dataloader for test data\n",
    "        test_dataset = self.fNIRSDataset(self.test_data, self.test_labels)\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    class fNIRSDataset(Dataset):\n",
    "        def __init__(self, data, labels):\n",
    "            self.data = torch.tensor(data, dtype=torch.float32)\n",
    "            self.labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            # Return a single sample (data, label)\n",
    "            return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data shape: (40, 23, 2424)\n",
      "Reshaped train data after SMOTE: (52, 23, 2424)\n",
      "Class distribution after SMOTE: Counter({0: 26, 1: 26})\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "df_10_1_Hz_truncated = Path('../../data/truncated/10_1_Hz')\n",
    "task_type = 'GNG'\n",
    "\n",
    "data_module = fNIRSDataModule(df_10_1_Hz_truncated, task_type, batch_size=8, oversampling=True)\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Dataset for Braindecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data shape: (69, 2424)\n",
      "Sample data HbO shape: (23, 2424)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "df_10_1_Hz_truncated = Path('../../data/truncated/10_1_Hz')\n",
    "task_type = 'GNG'\n",
    "\n",
    "fNIRS_data_dict = du.load_concatenated_fNIRS_data(df_10_1_Hz_truncated, task_type)\n",
    "data, labels = du.create_data_and_labels(fNIRS_data_dict)\n",
    "\n",
    "sample_idx = np.random.randint(len(data))\n",
    "sample_data = data[sample_idx]\n",
    "sample_label = labels[sample_idx]\n",
    "\n",
    "# Check the shape\n",
    "print(f\"Sample data shape: {sample_data.shape}\")  # Should print (channels, time\n",
    "\n",
    "# Extract the HbO only Data which is the first index to 23rd index\n",
    "sample_data_hbo = sample_data[:23]\n",
    "print(f\"Sample data HbO shape: {sample_data_hbo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=23, n_times=2424\n",
      "    Range : 0 ... 2423 =      0.000 ...   239.901 secs\n",
      "Ready.\n",
      "[{'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S1_D1 hbo', 'scanno': 1, 'logno': 1}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S1_D2 hbo', 'scanno': 2, 'logno': 2}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S2_D1 hbo', 'scanno': 3, 'logno': 3}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S2_D2 hbo', 'scanno': 4, 'logno': 4}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S3_D1 hbo', 'scanno': 5, 'logno': 5}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S3_D2 hbo', 'scanno': 6, 'logno': 6}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S4_D1 hbo', 'scanno': 7, 'logno': 7}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S4_D2 hbo', 'scanno': 8, 'logno': 8}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S5_D1 hbo', 'scanno': 9, 'logno': 9}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S5_D2 hbo', 'scanno': 10, 'logno': 10}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S6_D1 hbo', 'scanno': 11, 'logno': 11}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S6_D2 hbo', 'scanno': 12, 'logno': 12}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S7_D1 hbo', 'scanno': 13, 'logno': 13}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S7_D2 hbo', 'scanno': 14, 'logno': 14}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S8_D1 hbo', 'scanno': 15, 'logno': 15}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S8_D2 hbo', 'scanno': 16, 'logno': 16}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S9_D1 hbo', 'scanno': 17, 'logno': 17}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S9_D2 hbo', 'scanno': 18, 'logno': 18}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S10_D1 hbo', 'scanno': 19, 'logno': 19}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S10_D2 hbo', 'scanno': 20, 'logno': 20}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S11_D1 hbo', 'scanno': 21, 'logno': 21}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S11_D2 hbo', 'scanno': 22, 'logno': 22}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 1100 (FIFFV_FNIRS_CH), 'coil_type': 300 (FIFFV_COIL_FNIRS_HBO), 'unit': 6 (FIFF_UNIT_MOL), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'S12_D1 hbo', 'scanno': 23, 'logno': 23}]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your data has 23 channels (HbO data) and 2424 time points\n",
    "data = np.random.rand(23, 2424)  # Replace this with your actual data\n",
    "\n",
    "# Define channel names for the 23 HbO channels (e.g., S1_D1, S2_D1, etc.)\n",
    "ch_names = [\n",
    "    \"S1_D1 hbo\", \"S1_D2 hbo\", \"S2_D1 hbo\", \"S2_D2 hbo\", \"S3_D1 hbo\", \n",
    "    \"S3_D2 hbo\", \"S4_D1 hbo\", \"S4_D2 hbo\", \"S5_D1 hbo\", \"S5_D2 hbo\",\n",
    "    \"S6_D1 hbo\", \"S6_D2 hbo\", \"S7_D1 hbo\", \"S7_D2 hbo\", \"S8_D1 hbo\",\n",
    "    \"S8_D2 hbo\", \"S9_D1 hbo\", \"S9_D2 hbo\", \"S10_D1 hbo\", \"S10_D2 hbo\",\n",
    "    \"S11_D1 hbo\", \"S11_D2 hbo\", \"S12_D1 hbo\"\n",
    "]\n",
    "\n",
    "# Define the channel types (all are 'hbo' for HbO)\n",
    "ch_types = [\"hbo\"] * 23\n",
    "\n",
    "# Sampling frequency of the data (adjust based on your data)\n",
    "sfreq = 10.1  # Adjust as needed\n",
    "\n",
    "# Create MNE Info object\n",
    "info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sfreq)\n",
    "\n",
    "# Create RawArray object for your data (optional, just to check the data structure)\n",
    "raw = mne.io.RawArray(data, info)\n",
    "\n",
    "# Extract the `info[\"chs\"]` to pass as `chs_info`\n",
    "chs_info = info[\"chs\"]\n",
    "\n",
    "print(chs_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create LightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MeanMetric\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryAUROC, BinaryConfusionMatrix\n",
    "import seaborn as sns\n",
    "\n",
    "class fNIRSModule(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_name, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = create_model(model_name)  # type: ignore # noqa: F821\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        self.example_input_array = torch.zeros(1, 23, 2424, dtype=torch.float32)\n",
    "\n",
    "        # Metrics for training\n",
    "        self.mean_train_loss = MeanMetric()\n",
    "        self.mean_train_acc = BinaryAccuracy()\n",
    "\n",
    "        # Metrics for validation\n",
    "        self.mean_valid_loss = MeanMetric()\n",
    "        self.mean_valid_acc = BinaryAccuracy()\n",
    "\n",
    "        # Metrics for testing\n",
    "        self.test_preds = []\n",
    "        self.test_targets = []\n",
    "        self.mean_test_acc = BinaryAccuracy()\n",
    "        self.test_f1 = BinaryF1Score()\n",
    "        self.test_auroc = BinaryAUROC()\n",
    "        self.test_conf_matrix = BinaryConfusionMatrix()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer_name == 'Adam':\n",
    "            optimizer = torch.optim.AdamW(self.model.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == 'SGD':\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f\"Unknown optimizer: {self.hparams.optimizer_name}\"\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[100, 150], gamma=0.1\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        data, target = batch\n",
    "        output = self.model(data)\n",
    "        loss = self.loss_module(output, target)\n",
    "        pred_batch = output.detach().argmax(dim=1)\n",
    "\n",
    "        self.mean_train_loss(loss, weight=data.shape[0])\n",
    "        self.mean_train_acc(pred_batch, target)\n",
    "\n",
    "        self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"train/batch_acc\", self.mean_train_acc, prog_bar=True, logger=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        data, target = batch\n",
    "        output = self.model(data)\n",
    "        loss = self.loss_module(output, target)\n",
    "        pred_batch = output.argmax(dim=1)\n",
    "\n",
    "        # Update validation metrics\n",
    "        self.mean_valid_loss(loss, weight=data.shape[0])    \n",
    "        self.mean_valid_acc(pred_batch, target)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, target = batch\n",
    "        output = self.model(data)\n",
    "        pred_batch = output.argmax(dim=1)\n",
    "\n",
    "        # Update test metrics (accuracy, F1 score, AUROC, and confusion matrix)\n",
    "        self.mean_test_acc(pred_batch, target)\n",
    "        \n",
    "        # Store predictions and labels for confusion matrix\n",
    "        self.test_preds.append(pred_batch)\n",
    "        self.test_targets.append(target)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate epoch level metrics for the validation set\"\"\"\n",
    "\n",
    "        self.log(\"valid/loss\", self.mean_valid_loss, prog_bar=True, logger=True, on_epoch=True)\n",
    "        self.log(\"valid/acc\", self.mean_valid_acc, prog_bar=True, logger=True, on_epoch=True)\n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        \"\"\"Calculate final metrics for the test set after all batches have been processed.\"\"\"\n",
    "        \n",
    "        # Concatenate all predictions and targets across batches\n",
    "        final_preds = torch.cat(self.test_preds)\n",
    "        final_targets = torch.cat(self.test_targets)\n",
    "\n",
    "        # Compute final test metrics\n",
    "        test_acc = self.mean_test_acc.compute()\n",
    "        test_f1 = self.test_f1(final_preds, final_targets)\n",
    "        test_auroc = self.test_auroc(final_preds, final_targets)\n",
    "        test_conf_matrix = self.test_conf_matrix(final_preds, final_targets)\n",
    "\n",
    "        # Move confusion matrix to CPU and convert to NumPy\n",
    "        test_conf_matrix_cpu = test_conf_matrix.cpu().numpy()\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        self.plot_confusion_matrix(test_conf_matrix_cpu)\n",
    "\n",
    "        # Log the final metrics\n",
    "        self.log(\"test/acc\", test_acc)\n",
    "        self.log(\"test/f1\", test_f1)\n",
    "        self.log(\"test/auroc\", test_auroc)\n",
    "\n",
    "        # Optionally print the confusion matrix\n",
    "        print(\"Test Confusion Matrix:\\n\", test_conf_matrix)\n",
    "\n",
    "        # Reset metrics for the next test run (if applicable)\n",
    "        self.test_f1.reset()\n",
    "        self.test_auroc.reset()\n",
    "        self.test_conf_matrix.reset()\n",
    "\n",
    "        # Clear stored predictions and targets\n",
    "        self.test_preds.clear()\n",
    "        self.test_targets.clear()\n",
    "\n",
    "    def plot_confusion_matrix(self, cm):\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax, \n",
    "                    xticklabels=['Predicted Healthy', 'Predicted Non-Healthy'], \n",
    "                    yticklabels=['Healthy', 'Non-Healthy'])\n",
    "        ax.set_xlabel(\"Predicted labels\")\n",
    "        ax.set_ylabel(\"True labels\")\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "        # Log confusion matrix to TensorBoard\n",
    "        self.logger.experiment.add_figure(\"Confusion Matrix\", fig, self.current_epoch)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, RichModelSummary\n",
    "CHECKPOINT_PATH = Path('./saved_models/tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    # Crreate a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                            # Where to save models\n",
    "                         accelerator='gpu' if str(device).startswith(\"cuda\") else \"cpu\",                       # We run on a GPU (if possible)\n",
    "                         devices=1,                                                                            # How many GPUs/CPUs we want to use (1 is enough for the notebooks)\n",
    "                         max_epochs=100,                                                                      # How many epochs to train for if no patience is set\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"valid/acc\"),    # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "                                    LearningRateMonitor(logging_interval='epoch'),\n",
    "                                    RichModelSummary(max_depth=3)],                            # Log learning rate every epoch\n",
    "                        enable_progress_bar=True,\n",
    "                        log_every_n_steps=1)                                                               \n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    pl.seed_everything(42)\n",
    "    model = fNIRSModule(model_name=model_name, **kwargs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "    model = fNIRSModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation set and test set (if available)\n",
    "    val_result = trainer.test(model, test_loader, verbose=False)\n",
    "\n",
    "    return model, val_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "def create_model(model_name):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name]\n",
    "    else:\n",
    "        assert False, f\"Unknown model name \\\"{model_name}\\\". Available models are: {str(model_dict.keys())}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. TCN (Temporal Convolutional Network) - Braindecode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Braindecode models:\n",
      "['ATCNet', 'Deep4Net', 'DeepSleepNet', 'EEGConformer', 'EEGITNet', 'EEGInception', 'EEGInceptionERP', 'EEGInceptionMI', 'EEGNetv1', 'EEGNetv4', 'EEGResNet', 'HybridNet', 'ShallowFBCSPNet', 'SleepStagerBlanco2020', 'SleepStagerChambon2018', 'SleepStagerEldele2021', 'TCN', 'TIDNet', 'USleep']\n",
      "======================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "======================================================================================================================================================\n",
      "TCN (TCN)                                          [1, 23, 2424]             [1, 2, 2304]              --                        --\n",
      "├─Ensure4d (ensuredims): 1-1                       [1, 23, 2424]             [1, 23, 2424, 1]          --                        --\n",
      "├─Sequential (temporal_blocks): 1-2                [1, 23, 2424]             [1, 64, 2424]             --                        --\n",
      "│    └─TemporalBlock (temporal_block_0): 2-1       [1, 23, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv1): 3-1                    [1, 23, 2424]             [1, 64, 2428]             7,488                     [5]\n",
      "│    │    └─Chomp1d (chomp1): 3-2                  [1, 64, 2428]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu1): 3-3                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout1): 3-4              [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv2): 3-5                    [1, 64, 2424]             [1, 64, 2428]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp2): 3-6                  [1, 64, 2428]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu2): 3-7                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout2): 3-8              [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (downsample): 3-9               [1, 23, 2424]             [1, 64, 2424]             1,536                     [1]\n",
      "│    │    └─ReLU (relu): 3-10                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    └─TemporalBlock (temporal_block_1): 2-2       [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv1): 3-11                   [1, 64, 2424]             [1, 64, 2432]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp1): 3-12                 [1, 64, 2432]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu1): 3-13                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout1): 3-14             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv2): 3-15                   [1, 64, 2424]             [1, 64, 2432]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp2): 3-16                 [1, 64, 2432]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu2): 3-17                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout2): 3-18             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu): 3-19                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    └─TemporalBlock (temporal_block_2): 2-3       [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv1): 3-20                   [1, 64, 2424]             [1, 64, 2440]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp1): 3-21                 [1, 64, 2440]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu1): 3-22                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout1): 3-23             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv2): 3-24                   [1, 64, 2424]             [1, 64, 2440]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp2): 3-25                 [1, 64, 2440]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu2): 3-26                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout2): 3-27             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu): 3-28                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    └─TemporalBlock (temporal_block_3): 2-4       [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv1): 3-29                   [1, 64, 2424]             [1, 64, 2456]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp1): 3-30                 [1, 64, 2456]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu1): 3-31                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout1): 3-32             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Conv1d (conv2): 3-33                   [1, 64, 2424]             [1, 64, 2456]             20,608                    [5]\n",
      "│    │    └─Chomp1d (chomp2): 3-34                 [1, 64, 2456]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu2): 3-35                     [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─Dropout2d (dropout2): 3-36             [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "│    │    └─ReLU (relu): 3-37                      [1, 64, 2424]             [1, 64, 2424]             --                        --\n",
      "├─_FinalLayer (final_layer): 1-3                   [1, 2424, 64]             [1, 2, 2304]              --                        --\n",
      "│    └─Linear (fc): 2-5                            [2424, 64]                [2424, 2]                 130                       --\n",
      "│    └─Identity (out_fun): 2-6                     [2424, 2]                 [2424, 2]                 --                        --\n",
      "│    └─Expression (squeeze): 2-7                   [1, 2, 2304, 1]           [1, 2, 2304]              --                        --\n",
      "======================================================================================================================================================\n",
      "Total params: 153,410\n",
      "Trainable params: 153,410\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 14.97\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 0.22\n",
      "Forward/backward pass size (MB): 11.27\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 12.11\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from braindecode.models.util import models_dict\n",
    "\n",
    "print(f'All the Braindecode models:\\n{list(models_dict.keys())}')\n",
    "\n",
    "from braindecode.models import TCN\n",
    "\n",
    "model = TCN(\n",
    "    n_chans=23, \n",
    "    n_outputs=2,\n",
    "    n_times=2424,\n",
    "    n_blocks=4, \n",
    "    n_filters=64,\n",
    "    kernel_size=5,\n",
    "    drop_prob=0.5,\n",
    "    chs_info=chs_info,\n",
    "    sfreq=10.1,\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\torch\\nn\\functional.py:1381: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">       In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      Out sizes </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ model                                  │ TCN            │  153 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 23, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 2, 2304] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ model.ensuredims                       │ Ensure4d       │      0 │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 23, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 23, 2424, </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    </span>│                                        │                │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             1] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ model.temporal_blocks                  │ Sequential     │  153 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 23, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ model.temporal_blocks.temporal_block_0 │ TemporalBlock  │ 29.6 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 23, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ model.temporal_blocks.temporal_block_1 │ TemporalBlock  │ 41.2 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ model.temporal_blocks.temporal_block_2 │ TemporalBlock  │ 41.2 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ model.temporal_blocks.temporal_block_3 │ TemporalBlock  │ 41.2 K │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 64, 2424] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ model.final_layer                      │ _FinalLayer    │    130 │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">     [[1, 2424, </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 2, 2304] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    </span>│                                        │                │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> 64], '?', '?', </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    </span>│                                        │                │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">           '?'] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ model.final_layer.fc                   │ Linear         │    130 │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">     [2424, 64] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">      [2424, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ model.final_layer.out_fun              │ Identity       │      0 │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">      [2424, 2] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">      [2424, 2] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ model.final_layer.squeeze              │ Expression     │      0 │ eval  │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 2, 2304, </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 2, 2304] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">    </span>│                                        │                │        │       │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             1] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ loss_module                            │ CrossEntropyL… │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ mean_train_loss                        │ MeanMetric     │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ mean_train_acc                         │ BinaryAccuracy │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ mean_valid_loss                        │ MeanMetric     │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>│ mean_valid_acc                         │ BinaryAccuracy │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>│ mean_test_acc                          │ BinaryAccuracy │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>│ test_f1                                │ BinaryF1Score  │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>│ test_auroc                             │ BinaryAUROC    │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>│ test_conf_matrix                       │ BinaryConfusi… │      0 │ train │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">              ? </span>│\n",
       "└────┴────────────────────────────────────────┴────────────────┴────────┴───────┴────────────────┴────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m      In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ model                                  │ TCN            │  153 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 23, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [1, 2, 2304]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ model.ensuredims                       │ Ensure4d       │      0 │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 23, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 23, 2424,\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m    \u001b[0m│                                        │                │        │       │\u001b[37m                \u001b[0m│\u001b[37m \u001b[0m\u001b[37m            1]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ model.temporal_blocks                  │ Sequential     │  153 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 23, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ model.temporal_blocks.temporal_block_0 │ TemporalBlock  │ 29.6 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 23, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ model.temporal_blocks.temporal_block_1 │ TemporalBlock  │ 41.2 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ model.temporal_blocks.temporal_block_2 │ TemporalBlock  │ 41.2 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ model.temporal_blocks.temporal_block_3 │ TemporalBlock  │ 41.2 K │ eval  │\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m [1, 64, 2424]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ model.final_layer                      │ _FinalLayer    │    130 │ eval  │\u001b[37m \u001b[0m\u001b[37m    [[1, 2424,\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [1, 2, 2304]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m    \u001b[0m│                                        │                │        │       │\u001b[37m \u001b[0m\u001b[37m64], '?', '?',\u001b[0m\u001b[37m \u001b[0m│\u001b[37m                \u001b[0m│\n",
       "│\u001b[2m    \u001b[0m│                                        │                │        │       │\u001b[37m \u001b[0m\u001b[37m          '?']\u001b[0m\u001b[37m \u001b[0m│\u001b[37m                \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ model.final_layer.fc                   │ Linear         │    130 │ eval  │\u001b[37m \u001b[0m\u001b[37m    [2424, 64]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m     [2424, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ model.final_layer.out_fun              │ Identity       │      0 │ eval  │\u001b[37m \u001b[0m\u001b[37m     [2424, 2]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m     [2424, 2]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ model.final_layer.squeeze              │ Expression     │      0 │ eval  │\u001b[37m \u001b[0m\u001b[37m  [1, 2, 2304,\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m  [1, 2, 2304]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m    \u001b[0m│                                        │                │        │       │\u001b[37m \u001b[0m\u001b[37m            1]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m                \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ loss_module                            │ CrossEntropyL… │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ mean_train_loss                        │ MeanMetric     │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ mean_train_acc                         │ BinaryAccuracy │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ mean_valid_loss                        │ MeanMetric     │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0m│ mean_valid_acc                         │ BinaryAccuracy │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0m│ mean_test_acc                          │ BinaryAccuracy │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0m│ test_f1                                │ BinaryF1Score  │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0m│ test_auroc                             │ BinaryAUROC    │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0m│ test_conf_matrix                       │ BinaryConfusi… │      0 │ train │\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m             ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└────┴────────────────────────────────────────┴────────────────┴────────┴───────┴────────────────┴────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 153 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 153 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 9                                                                                           \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 48                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 153 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 153 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 9                                                                                           \n",
       "\u001b[1mModules in eval mode\u001b[0m: 48                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\braindecode\\models\\tcn.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert time_size >= self.min_len\n",
      "c:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\braindecode\\models\\tcn.py:148: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  out_size = 1 + max(0, time_size - min_len)\n",
      "c:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\braindecode\\models\\functions.py:32: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.size()[3] == 1\n",
      "c:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\braindecode\\models\\functions.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.size()[2] == 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1ac89191df4d8d9267ab57099a442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO X1E\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [8, 2304], got [8]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTCN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m----> 3\u001b[0m tcn_model, tcn_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTCN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43moptimizer_hparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model_name, save_name, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m pl\u001b[38;5;241m.\u001b[39mseed_everything(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m fNIRSModule(model_name\u001b[38;5;241m=\u001b[39mmodel_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m fNIRSModule\u001b[38;5;241m.\u001b[39mload_from_checkpoint(trainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path) \u001b[38;5;66;03m# Load best checkpoint after training\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Test best model on validation set and test set (if available)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    395\u001b[0m )\n\u001b[1;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\strategies\\strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[20], line 72\u001b[0m, in \u001b[0;36mfNIRSModule.validation_step\u001b[1;34m(self, batch, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m data, target \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     71\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n\u001b[1;32m---> 72\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m pred_batch \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Update validation metrics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\fnirs\\lib\\site-packages\\torch\\nn\\functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [8, 2304], got [8]"
     ]
    }
   ],
   "source": [
    "model_dict[\"TCN\"] = model\n",
    "\n",
    "tcn_model, tcn_results = train_model(model_name=\"TCN\",\n",
    "                                     optimizer_name=\"Adam\",\n",
    "                                     optimizer_hparams={\"lr\": 1e-3, \n",
    "                                                        \"weight_decay\": 1e-4})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnirs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
